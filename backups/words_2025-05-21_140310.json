{
    "β‐VAE": {
        "meaning": "変分オートエンコーダに正則化項を追加したモデル",
        "memo": "潜在空間の独立性を強化し、解釈可能な特徴抽出を目指す。"
    },
    "infoVAE": {
        "meaning": "情報理論を導入した変分オートエンコーダ",
        "memo": "潜在変数と生成データの相互情報量を最大化することで、より意味のある生成を行う。"
    },
    "VQ-VAE": {
        "meaning": "ベクトル量子化を利用しタオートエンコーダ",
        "memo": "潜在空間を離散化することで、生成モデルの学習を改善。音声や画像生成に利用される。"
    },
    "潜在変数": {
        "meaning": "観測できないがモデル内部で表現される隠れた変数",
        "memo": "オートエンコーダやVAEの内部で、データの圧縮表現として扱われる。"
    },
    "統計分布": {
        "meaning": "データがどのように分布しているかを示す関数",
        "memo": "正規分布、ポアソン分布、ベルヌーイ分布など、データの特徴を把握するために使用。"
    },
    "事前学習": {
        "meaning": "大規模データで汎用的知識を獲得する仕組み",
        "memo": "ラベルなしデータを用いて文法・意味・構文などの一般知識を学習。下流タスクへの転移学習の基盤となる。"
    },
    "デコード": {
        "meaning": "圧縮された潜在空間から元のデータを再構成する処理",
        "memo": "潜在変数をもとに、元データ形式に近い形で出力を生成する。"
    },
    "エンコード": {
        "meaning": "データを低次元の潜在空間に圧縮する処理",
        "memo": "入力コードの特徴を抽出し、圧縮された表現に変換する。"
    },
    "オートエンコーダ": {
        "meaning": "データを圧縮・再構成するためのニューラルネットワーク",
        "memo": "入力データを低次元の潜在空間に圧縮(エンコード)し、そこから元のデータを再構成(デコード)する。"
    },
    "可視層": {
        "meaning": "データの入力や出力を受け持つ層",
        "memo": "データをネットワーク2入力したり、出力として取得する部分。オートエンコーダではエンコーダとデコーダの両方に存在する。"
    },
    "Multi-Head Attention ": {
        "meaning": "複数のSelf-Attentionを並列に実行する仕組み",
        "memo": "多様な視点から系列データを解析することで、文脈理解の精度を高める。"
    },
    "バリュー": {
        "meaning": "Self-Attentionにおいて実際の出力に使用されるベクトル",
        "memo": "関連性に基づいて加重平均され、最終的な出力の計算に使われる。"
    },
    "キー": {
        "meaning": "Self-Attentionにおいて関連性を判断するためのベクトル",
        "memo": "各単語が持つ情報の「キー」を示し、他の単語との関連性を評価する。"
    },
    "クエリ": {
        "meaning": "Self-Attentionにおいて関連性を求めるためのベクトル",
        "memo": "対象の単語が他の単語にどれだけ依存するかを計算する。\n"
    },
    "位置エンコーディング": {
        "meaning": "入力系列の順序情報を付与する処理",
        "memo": "Self-Attentionは系列の順番を持たないため、位置情報を追加して順序を認識させる。"
    },
    "Self-Attention": {
        "meaning": "系列内の要素同士の関連性を学習する注意機構",
        "memo": "各単語が系列内の他の単語にどれだけ関連するかを計算し、文脈理解を深める。"
    },
    "Encoder-Decoder Attention": {
        "meaning": "エンコーダの出力を基にデコーダが重み付けを行う仕組み",
        "memo": "入力系列の重要部分に焦点を当てて、デコーダの出力を生成する。"
    },
    "Source-Target Attention": {
        "meaning": "エンコーダとデコーダ間の注意機構",
        "memo": "エンコーダーの出力をもとにデコーダが重要な情報に集中する仕組み。翻訳や要約などで使われる。"
    },
    "Attention": {
        "meaning": "入力系列の重要な部分に重みをつけて学習する手法",
        "memo": "翻訳や要約で効果を発揮し、重要な単語や特徴に重点を置いて処理を行う。"
    },
    "教師強制": {
        "meaning": "sequence-to-sequenceモデルの学習時に正解データを使用する手法",
        "memo": "学習中に実際の正解データを強制的に次のステップに渡すことで安定化を図る。"
    },
    "Image  Captioning": {
        "meaning": "画像の内容を文章として説明する技術",
        "memo": "CNNで画像特徴を抽出し、RNNでキャプションを生成する。"
    },
    "デコーダ": {
        "meaning": "内部表現をもとに系列データを生成するネットワーク",
        "memo": "エンコーダで圧縮された情報を基に出力データを生成する。"
    },
    "エンコーダ": {
        "meaning": "系列データを内部表現に変換するネットワーク",
        "memo": "入力された系列データを圧縮して内部表現に変換する。"
    },
    "sequence-to-sequence": {
        "meaning": "系列データから系列データを生成するモデル",
        "memo": "翻訳や要約生成など、入力と出力が異なる長さのタスクに使用される。"
    },
    "Bidirectional RNN": {
        "meaning": "順方向と逆方向に伝播するRNN",
        "memo": "前後のコンテキスト情報を考慮して学習を行う。"
    },
    "更新ゲート": {
        "meaning": "GRUにおいて新しい情報の追加を制御する役割",
        "memo": "新しいデータの影響度を調整し、長期的な依存関係を学習する。"
    },
    "リセットゲート": {
        "meaning": "GRUにおいて過去の記憶をリセットする役割",
        "memo": "無関係な情報をリセットし、効率的な学習を実現する。"
    },
    "GRU": {
        "meaning": "LSTMの簡略版で2つのゲートのみを持つ構造",
        "memo": "パラメータが少なく、計算効率が高い。"
    },
    "忘却ゲート": {
        "meaning": "セルの状態をどれだけ保持するかを制御するゲート",
        "memo": "不要な情報を削除し、学習効率を改善する役割を持つ。"
    },
    "出力ゲート": {
        "meaning": "内部状態から出力を生成するゲート",
        "memo": "LSTMの内部記憶を次の隠れ層へ出力する役割を担う。"
    },
    "入力ゲート": {
        "meaning": "新たな情報をセル状態に追加する役割を持つゲート",
        "memo": "入力データのうち、どれだけ内部状態に追加するかを制御する。"
    },
    "CEC(Constant Error Carousel)": {
        "meaning": "誤差を内部に留めて伝播させるメカニズム",
        "memo": "誤差が減衰せず、長期依存の学習が可能となる。"
    },
    "LSTMブロック": {
        "meaning": "LSTMの基本構造単位",
        "memo": "複数のゲート(入力、出力、忘却)と記憶セル(CEC)から構成される。"
    },
    "LSTM": {
        "meaning": "長期依存関係を学習可能なRNNの拡張版",
        "memo": "勾配消失問題を解決するために開発され、入力ゲート、出力ゲート、忘却ゲートを持つ。"
    },
    "出力重み衝突": {
        "meaning": "複数の出力が重みを通じて干渉し合い、誤差が増大する現象。",
        "memo": "次のステップへの影響が不安定になることで、学習が遅延する。"
    },
    "入力重み衝突": {
        "meaning": "複数の入力が同時に影響し合い、学習が不安定になる現象",
        "memo": "時系列データにおいて、関連の強い入力同士が干渉する。"
    },
    "勾配消失問題": {
        "meaning": "勾配が小さくなりすぎて学習が進まない問題",
        "memo": "シグモイド関数やTanh関数で発生しやすい。深いネットワークで多発。"
    },
    "ジョルダンネットワーク": {
        "meaning": "RNNの一種で出力を次のステップに戻す構造",
        "memo": "出力層の結果を次の入力へフィードバックする構造。短期の時系列データに強い。"
    },
    "エルマンネットワーク": {
        "meaning": "単純なRNNの一種",
        "memo": "隠れ層の出力を次の入力へフィードバックする構造。短期の時系列データに強い。"
    },
    " Pretrained Models": {
        "meaning": "事前に大規模データで学習されたモデル",
        "memo": "BERT、GPT、RoBERTaなど、転移学習で利用される。大規模データでの学習済みで高精度な結果を出力する。"
    },
    "言語モデル": {
        "meaning": "文章の出現確率を予測するモデル",
        "memo": "次に来る単語や文章全体の確率を計算し、文章生成や文脈理解に利用される。"
    },
    "リカレントニューラルネットワーク(RNN)": {
        "meaning": "自系列データや系列データを扱うためのニューラルネットワーク",
        "memo": "前の時間ステップの情報を保持し、次のステップに引き継ぐことで、連続したデータの学習が可能。"
    },
    "グループ正規化": {
        "meaning": "複数のチャンネルをグループに分けて正規化",
        "memo": "バッチサイズに依存せず安定した学習を実現。小規模バッチでも有効。"
    },
    "インスタンス正規化": {
        "meaning": "各サンプルごとに正規化を行う手法",
        "memo": "画像生成モデルなどで使用され、スタイル変換で効果的。"
    },
    "レイヤー正規化": {
        "meaning": "各レイヤー内のニューロン単位で正則化する手法",
        "memo": "RNNやTransformerなど、バッチサイズに依存しないモデルで有効。"
    },
    "バッチ正則化": {
        "meaning": "バッチごとに平均と分散を用いて正規化する手法。",
        "memo": "学習を高速化し、初期値や学習率への依存を減らす。"
    },
    "正規化処理": {
        "meaning": "データ分布を調整し学習を安定化する処理",
        "memo": "内部共変量シフトを抑制し、学習効率を改善する。"
    },
    "ResNet": {
        "meaning": "スキップ結合を用いたディープニューラルネットワーク",
        "memo": "非常に深いネットワークでも学習が可能。スキップ結合により勾配消失問題を解決。"
    },
    "スキップ結合": {
        "meaning": "層をまたいで出力する手法",
        "memo": "学習の停滞を紡ぎ、勾配消失問題を緩和する。ResNetに代表される。"
    },
    "Global Average Pooling": {
        "meaning": "特徴マップ全体の平均値を出力する手法",
        "memo": "全結合層の代替として用いられ、パラメータ数を削減する。"
    },
    "全結合層": {
        "meaning": "すべてのニューロンが接続される層",
        "memo": "畳み込み層の後段に用いられ、最終的な判断を行う。"
    },
    "不変性": {
        "meaning": "変化しても出力が変わらない性質",
        "memo": "位置、回転、スケールなどに対する安定性。"
    },
    "平均値プーリング": {
        "meaning": "領域内の平均値を出力するプーリング手法",
        "memo": "特徴のなだらかな要約に使われる。"
    },
    "最大値プーリング": {
        "meaning": "領域内の最大値を出力するプーリング手法",
        "memo": "特徴量の抽出に使われ、ノイズ耐性をもつ。"
    },
    "ダウンサンプリング(サブサンプリング)": {
        "meaning": "データを間引いてサイズを縮小する処理",
        "memo": "プーリング層やストライドで実現される。"
    },
    "プーリング層": {
        "meaning": "特徴マップのダウンサンプリングを行う",
        "memo": "特徴量の空間サイズを縮小し、計算負荷と過学習を抑制する。"
    },
    "Pointwise Convolution": {
        "meaning": "1×1のカーネルを用いた畳み込み処理",
        "memo": "チャンネル間の結合を行う。Depthwise Convolutionの後に適用される。"
    },
    "Depthwise Convolution": {
        "meaning": "チャンネル事に個別に畳み込み処理",
        "memo": "各チャンネルに独立したカーネルを適用する。"
    },
    "Depthwise Separable Convolution": {
        "meaning": "空間方向とチャンネル方向を分けて畳み込む手法",
        "memo": "Depthwise ConvolutionとPointwise Convolutionの組み合わせで、計算効率を高める。"
    },
    "Atrous Convolution(Dilated Convolution)": {
        "meaning": "間隔を空けたカーネル適用による畳み込み処理",
        "memo": "有効受容野を広げつつ、計算量を増やさずに特徴を捉える手法。"
    },
    "ストライド": {
        "meaning": "カーネルを適用する際の移動幅",
        "memo": "大きいほど出力が縮小され、計算量が減少する。"
    },
    "バディング処理": {
        "meaning": "入力データの周囲に0などを加える処理",
        "memo": "出力サイズを調整するために行う。ゼロパティングが一般的。"
    },
    "カーネル(フィルタ)": {
        "meaning": "特徴抽出のために用いる重み行列",
        "memo": "畳み込み処理で用いられる小さな重み行列。特徴検出の役割を持つ。"
    },
    "畳み込み処理": {
        "meaning": "カーネルを使って特徴を抽出する演算",
        "memo": "カーネルをデータにスライド適用し、内積を計算して特徴マップを生成する。"
    },
    "畳み込み層": {
        "meaning": "カーネルを用いて特徴を抽出する層",
        "memo": "画像や信号データから局所的特徴を抽出する。CNNの基本的な構成要素。"
    },
    "Randomized ReLU": {
        "meaning": "LeakyReLUの勾配をランダムに決める活性化関数",
        "memo": "学習時に負の領域の傾きをランダムに決め、汎化性能向上を狙う。"
    },
    "Parametric ReLU": {
        "meaning": "LeakyReLUの勾配を学習可能にした活性化関数",
        "memo": "負の領域の勾配をパラメータとして学習できるようにした改良版。"
    },
    "Leaky ReLU関数": {
        "meaning": "ReLUの変種で、０以下もわずかに勾配を持つ関数",
        "memo": "勾配が0になる問題を回避するため、負の領域でも微小な傾きを持つ。"
    },
    "ReLU関数": {
        "meaning": "0以下は0、0より大きければそのまま出力する活性化関数",
        "memo": "勾配消失問題を緩和する効果があり、DNNで広く使用される。"
    },
    "Tnsh関数": {
        "meaning": "出力が-1から1に収まるS字型活性化関数",
        "memo": "Sigmoid関数と似るが、出力の中心が0であり、学習が安定しやすい。"
    },
    "導関数": {
        "meaning": "関数の微分係数",
        "memo": "関数の変化率を表す。勾配降下法や最適化において基本となる概念。"
    },
    "勾配爆発問題": {
        "meaning": "勾配が大きくなりすぎて学習が不安定になる問題",
        "memo": "RNNや深いネットワークで起こりやすい。勾配クリッピングで対処されることが多い。"
    },
    "信用割当問題": {
        "meaning": "どの行動が報酬に貢献したかを特定する問題",
        "memo": "強化学習などで、結果に対してどの要素がどのくらい貢献したかを適切に割り当てる必要がある問題。"
    },
    "連鎖率": {
        "meaning": "合成関数の微分を行う公式",
        "memo": "各関数の微分を順番に掛け合わせることで、全体の微分が求まる。"
    },
    "合成関数の微分": {
        "meaning": "複数の関数を合成した場合の微分",
        "memo": "連鎖律(チェーンルール)を用いて複数の関数を順に微分する。誤差逆伝播法の基盤。"
    },
    "遺伝子的アルゴリズム": {
        "meaning": "生物の進化過程を模倣した最適化アルゴリズム",
        "memo": "交叉、突然変異、選択を繰り返しながら最適解を探索する進化的手法。"
    },
    "ベイズ最適化": {
        "meaning": "確率モデルを用いてハイパーパラメータ探索を効率化する手法",
        "memo": "探索履歴を考慮しつつ、効果的に次の探索点を決める。"
    },
    "ランダムサーチ": {
        "meaning": "ランダムにハイパーパラメータを選んで探索する手法",
        "memo": "探索空間の無駄を省き、計算負担を軽減できる。"
    },
    "グリッドサーチ": {
        "meaning": "ハイパーパラメータの組み合わせを網羅的に探索する手法",
        "memo": "すべてのパラメータ候補を試すため計算コストが高いが、確実性がある。"
    },
    "ハイパーパラメータチューニング": {
        "meaning": "最適なハイパーパラメータを探索する作業",
        "memo": "学習率、バッチサイズ、層の数などの調整。性能向上のために重要。"
    },
    "二重降下現象": {
        "meaning": "モデルが大きくなるほど一旦過学習し、その後また汎化性能が上がる現象",
        "memo": "伝統的なU字型の汎化曲線を超え、過学習を一旦超えたあと性能が再び改善する。"
    },
    "ノーフリーランチ定理": {
        "meaning": "すべての問題に最適な学習アルゴリズムは存在しないという理論",
        "memo": "アルゴリズムの優劣は問題設定に依存する。どんな場合も勝てる方法はない。"
    },
    "早期終了": {
        "meaning": "検証データで性能が改善しなくなったら学習を停止する手法",
        "memo": "過学習を防ぐため、一定期間性能が向上しない場合に学習を打ち切る。"
    },
    "AMSBound": {
        "meaning": "AdaBoundの変種で安定性を向上した手法",
        "memo": "AdaBoundの改良版。学習率の変動をさらに制限して安定化。"
    },
    "AdaBound": {
        "meaning": "Adamに境界制約を加えた手法",
        "memo": "学習率が極端に大きくも小さくもならないように調整。"
    },
    "Adam": {
        "meaning": "モーメンタムとRMSpropを組み合わせた最適化手法",
        "memo": "最適化アルゴリズムのデファクトスタンダード。１次モーメンタムを利用。"
    },
    "RMSprop": {
        "meaning": "勾配の平方の移動平均で学習率を調整する手法",
        "memo": "Adagradの改良版で、学習率が過度に減衰するのを防ぐ。"
    },
    "Adadelta": {
        "meaning": "Adagradの過学習を抑える改良版",
        "memo": "累積平方勾配の減衰平均を使い、学習率が極端に小さくなる問題を解決。"
    },
    "Adagrad": {
        "meaning": "勾配の大きさに応じて学習率を自動調整する手法",
        "memo": "頻繁に更新されるパラメータの学習率を減少させる。スパースデータに強い。"
    },
    "モーメンタム": {
        "meaning": "過去の勾配情報を加味して更新する最適化手法",
        "memo": "慣性を利用して局所最適や鞍点を突破しやすくする手法。"
    },
    "プラトー": {
        "meaning": "損失関数の変化が非常に小さい平坦な領域",
        "memo": "学習が進みにくく停滞しやすいエリア。更新が難しい。"
    },
    "鞍点": {
        "meaning": "ある方向では最小、別の方向では最大となる点",
        "memo": "勾配がゼロになるが最適解ではない点。高次元空間で多く発生する。"
    },
    "大域最適解": {
        "meaning": "全ての候補の中で最も良い解",
        "memo": "最適化問題の解空間全体を考慮したときの真の最適解。"
    },
    "局所最適解": {
        "meaning": "その近傍では最も良いが、全体では最適でない解",
        "memo": "最適化において、より良い解が他に存在する可能性があるが、近くに改善点がない状態。"
    },
    "ミニバッチ学習": {
        "meaning": "ミニバッチ単位で学習を行う方式",
        "memo": "一般的に広く用いられる効率的な学習方式。"
    },
    "バッチサイズ": {
        "meaning": "一回の勾配計算に使うデータの数",
        "memo": "小さいとノイズが多く、大きいと計算コストが高い。適切なサイズ設定が必要。"
    },
    "ミニバッチ": {
        "meaning": "勾配計算に使う少数のデータセット",
        "memo": "ミニバッチサイズ(バッチサイズ)を適切に設定することで効率的な学習が可能。"
    },
    "ミニバッチ勾配降下法": {
        "meaning": "データを小さなグループ(ミニバッチ)に分けて学習する手法",
        "memo": "SGDとバッチ学習の中間的手法。安定性と効率性を兼ね備える。"
    },
    "エポック": {
        "meaning": "全データセットを１回学習する単位",
        "memo": "何回学習データを繰り返して使うかを表す指標。"
    },
    "オンライン学習": {
        "meaning": "データが到着するたびに逐次学習を行う方式",
        "memo": "大規模データや逐次変化するデータに対応可能。"
    },
    "確率的勾配降下法": {
        "meaning": "１サンプルずつランダムに選んで更新する勾配法",
        "memo": "高速だがノイズが多い。局所最適解を回避しやすい。"
    },
    "最急降下法": {
        "meaning": "勾配降下法と同義。最も急な勾配方向に沿って更新。",
        "memo": "最も急激に損失を減少させる方向を選ぶ。"
    },
    "バッチ学習": {
        "meaning": "バッチ単位でデータをまとめて学習する手法",
        "memo": "全データを用いて一括更新。メモリ消費が大きいが安定性が高い。"
    },
    "バッチ": {
        "meaning": "一度にまとめて処理するデータの単位",
        "memo": "勾配計算の単位となるデータ集合。"
    },
    "バッチ勾配降下法": {
        "meaning": "すべてのデータを用いて勾配計算を行う最適化手法",
        "memo": "計算は安定するが、大規模データでは非効率。"
    },
    "学習率": {
        "meaning": "勾配に対する更新量を決めるハイパーパラメータ",
        "memo": "学習率が大きすぎると発散、小さすぎると収束が遅い。適切な調整が必要。"
    },
    "イテレーション": {
        "meaning": "パラメータ更新の1回分の繰り返し",
        "memo": "1回の学習ステップを指す。エポック内の更新回数に相当。"
    },
    "接線の傾き": {
        "meaning": "ある点での関数の変化率",
        "memo": "関数の接戦の傾きが勾配降下法で更新方向となる。"
    },
    "微分値": {
        "meaning": "関数の変化率(勾配)",
        "memo": "勾配降下法における方向と傾きを決定する基礎的な概念。"
    },
    "勾配降下法": {
        "meaning": "損失関数の最小値を求めるための最適化アルゴリズム",
        "memo": "勾配(微分値)を使い、損失関数を最小にする方向へパラメータを更新する。"
    },
    "ドロップアウト": {
        "meaning": "ニューラルネットの学習時にランダムにユニットを無効化する手法",
        "memo": "学習中に一部のノードを無効化し、依存を防ぐことで汎化性能を向上。"
    },
    "Elastic Net": {
        "meaning": "L1正則化、L2正則化を組み合わせた手法",
        "memo": "L１による特徴選択効果とL2による安定化効果の両方を得るために設計された正則化手法。"
    },
    "L0正則化": {
        "meaning": "重みが非ゼロである要素数にペナルティを課す正則化",
        "memo": "最も厳密な特徴選択効果となるが、計算困難なため近似手法が用いられる。"
    },
    "ノルム": {
        "meaning": "ベクトルの長さや大きさを測る指標",
        "memo": "L1ノルム(絶対値の合計)、L2ノルム(二乗和の平方根)などがあり、正則化項に使われる。"
    },
    "L2正則化": {
        "meaning": "重みの二重の合計にペナルティを課す正則化",
        "memo": "重みを小さく抑えつつ、すべての特徴を使う傾向にある。リッジ回帰で使用される。"
    },
    "L１正則化": {
        "meaning": "重みの絶対値の合計にペナルティを課す正則化",
        "memo": "重みを0にしやすく、特徴選択効果がある。ラッソ回帰に用いられる。"
    },
    "ペナルティ項": {
        "meaning": "過学習抑制のために課す罰則項",
        "memo": "モデルの重みや複雑さに制約を加え、過学習を防ぐ目的で正則化項として導入される。"
    },
    "正則化": {
        "meaning": "モデルの複雑さにペナルティを課して過学習を防ぐ手法。",
        "memo": "重みの大きさなどに罰則を加えることで、モデルの汎化性能を向上。L１正則化やL2正則化などがある。"
    },
    "目的関数": {
        "meaning": "最適化で最大化または最小化する関数",
        "memo": "損失関数も目的関数の一種。学習や推論における最適化の基準となる。"
    },
    "変分オートエンコーダー": {
        "meaning": "確率的生成モデルを用いたオートエンコーダー",
        "memo": "潜在変数を確率分布で表現し、新しいデータの生成や再構成が可能な深層生成モデル。"
    },
    "深層生成モデル": {
        "meaning": "学習を用いた生成モデル",
        "memo": "GAN、VAEなど、深層ニューラルネットを用いてデータを生成するモデル群。"
    },
    "JSダイバージェンス": {
        "meaning": "イェンゼン・シャノン情報量と同義",
        "memo": "KLダイバージェンスの対象版で、安定性に優れる。"
    },
    "KLダイバージェンス": {
        "meaning": "カルバック・ライブラー情報量と同義",
        "memo": "確率分布間のずれを測る非対称な指標。交差エントロピーと密接に関連。"
    },
    "イェンゼン・シャノン情報量": {
        "meaning": "対称化されたKLダイバージェンス",
        "memo": "KLダイバージェンスを対象にして安定化した指標。確率分布の類似度評価に用いられる。"
    },
    "カルバック・ライブラー情報量": {
        "meaning": "2つの確率分布の差を測る指標",
        "memo": "ある確率分布から別の確率分布への情報量のズレを測定。非対称。"
    },
    "生成モデル": {
        "meaning": "データを生成する能力を持つモデル",
        "memo": "データの潜在構造を学習し、新たなサンプルを生成可能。GAN、VAEなどが代表例。"
    },
    "生成問題": {
        "meaning": "新たなデータを生成するタスク",
        "memo": "画像生成、文章生成など、新しいデータを学習済みモデルから生成する問題設定。"
    },
    "Triplet Loss": {
        "meaning": "アンカーとポジティブネガティブ間の距離関係を最適化する損失関数",
        "memo": "Triplet Networkで使用され、正例は近く、負例は遠くするように学習。"
    },
    "Contrastiv Loss": {
        "meaning": "類似ペアと非類似ペアの距離を最適化する損失関数",
        "memo": "Siamese Networkで使われる。類似ペアは距離を小さく、非類似ペアは距離を大きく学習する。"
    },
    "Triplet Network": {
        "meaning": "アンカー・ポジティブ・ネガティブの３組を使う距離学習モデル",
        "memo": "正例と負例の距離差を学習し、識別性能を高めるネットワーク構造。"
    },
    "Siamese Network": {
        "meaning": "同一構造のネットワークを並列して用いる距離学習モデル",
        "memo": "2つの入力の特徴を比較し、類似度を計算する深層学習モデル。顔認証などで用いられる。"
    },
    "深層距離学習": {
        "meaning": "ニューラルネットを用いた距離学習",
        "memo": "深層ネットワークで特徴表現を学習し、距離ベースのタスク(類似判定・顔認識など)に応用する。"
    },
    "距離学習": {
        "meaning": "特徴間の距離関係を学習する手法群",
        "memo": "特徴ベクトル間の類似度や距離を適切に学習し、識別・類似検索に活用する。"
    },
    "微分計算": {
        "meaning": "関数の変化率を求める計算",
        "memo": "勾配降下法など最適化アルゴリズムで使用され、損失関数の最小化に必要な勾配を求める。"
    },
    "交差エントロピー誤差関数": {
        "meaning": "分類問題における交差エントロピーを用いた誤差関数",
        "memo": "正解ラベルと予測確率分布とのずれを評価し、分類タスクにおける損失関数として使用される。"
    },
    "交差エントロピー": {
        "meaning": "確率分布間の差を測る指標",
        "memo": "2つの確率分布間のずれを計測する。分類問題における誤差関数(損失関数)として広く用いられる。"
    },
    "バーニーおじさんのルール": {
        "meaning": "1グラム１ギガフロップスを目指すという指標",
        "memo": "NVIDIAのバーニー・マイヤース氏による省エネと高性能を両立する設計方針。"
    },
    "TPU": {
        "meaning": "Googleが開発したAI向け専用プロセッサ",
        "memo": "Tensor  Processing Unit.\nディープラーニング専用設計で高効率な行列演算を実現。"
    },
    "NVIDIA": {
        "meaning": "GPU、半導体チップ及びAI計算機ハードウェアの大手企業",
        "memo": "GPGPU技術を推進し、ディープラーニング用GPU(CUDA、Tensor Core)を開発。"
    },
    "GPGPU": {
        "meaning": "GPUを汎用計算に用いる技術",
        "memo": "GPUの並列計算能力を画像処理以外の科学技術計算に応用する手法。"
    },
    "GPU": {
        "meaning": "画像処理向け演算装置",
        "memo": "並列処理能力が高く、ディープラーニングや科学計算でも利用される。"
    },
    "CPU": {
        "meaning": "中央演算処理装置",
        "memo": "コンピュータの頭脳。制御、演算、記憶装置間の調整を行う。"
    },
    "ムーアの法則": {
        "meaning": "半導体集積度が約２年ごとに倍増するという経験則",
        "memo": "集積回路の性能向上とコスト低下を説明する歴史的な指標。現在は限界が指摘されている。"
    },
    "ハードウェアの制約と進歩": {
        "meaning": "計算資源の制約とその技術的発展",
        "memo": "計算速度、メモリ、消費電力などの制約と、それを克服するための技術革新。"
    },
    "ハードウェア": {
        "meaning": "物理的な機器や装置",
        "memo": "CPU、GPU、メモリなど、実体として存在する計算機資源。"
    },
    "ソフトウェア": {
        "meaning": "プログラムやアルゴリズムなどの非物理的機能部分",
        "memo": "ハードウェア上で動作し、データ処理や制御を行う。"
    },
    "半導体": {
        "meaning": "導電性を制御できる材料",
        "memo": "シリコンなどを用い、トランジスタや集積回路を構成。電子機器の基盤技術。"
    },
    "ディープニューラルネットワーク": {
        "meaning": "多層の隠れ層を持つニューラルネットワーク",
        "memo": "深層学習の基盤となるモデルで、複雑な非線形関係を表現できる。"
    },
    "損失関数": {
        "meaning": "誤差関数を学習時に最適化する目的関数として用いたもの",
        "memo": "学習アルゴリズムで最小化される指標。誤差関数とほぼ同義で使われるが、最適化対象という点を強調して損失関数と呼ぶ。"
    },
    "誤差関数": {
        "meaning": "予測値と正解値のズレ(誤差)を測る数式表現",
        "memo": "回帰や分類タスクにおける予測結果と実測データの差を計算する関数。モデルの性能を測る基準となる。"
    },
    "ハイパーパラメータ": {
        "meaning": "学習過程であらかじめ設定する調整項",
        "memo": "学習率、層の数、ユニット数など。パラメータとは異なり学習中に更新されない。"
    },
    "パラメータ": {
        "meaning": "学習によって最適化される値(重み・バイアス)",
        "memo": "モデル内部の学習対称となる数値。学習プロセスで更新される。"
    },
    "隠れ層": {
        "meaning": "入力層と出力層の間に存在する中間層",
        "memo": "複数の層を持つことで複数のパターンや特徴を表現できる。"
    },
    "活性化関数": {
        "meaning": "ニューロンの出力を決める非線形関数",
        "memo": "線形関数だけでは学習できない複雑なパターンを扱うために必要。ReLU、Sigmoid、Tanhなどが一般的に使用される。"
    },
    "重み": {
        "meaning": "ニューラルネットワークの基本構成要素",
        "memo": "各接続の強さを表すパラメータ。"
    },
    "出力層": {
        "meaning": "ニューラルネットワークの基本構成要素",
        "memo": "最終的な予測結果。"
    },
    "入力層": {
        "meaning": "ニューラルネットワークの基本構成要素",
        "memo": "データの受け取り口。"
    },
    "単純パーセプトロン": {
        "meaning": "最も基本的なニューラルネットワークモデル",
        "memo": "入力を重み付きで加算し、活性化関数で出力を決定。線形分離可能な問題に対応できる。"
    },
    "神経回路": {
        "meaning": "複数のニューロンが接続された構造",
        "memo": "生物では脳内ネットワーク、人工知能ではニューラルネットワークの基礎構造を指す。"
    },
    "ニューロン": {
        "meaning": "脳内の情報伝達を行う神経細胞",
        "memo": "生物の神経細胞を模倣し、人工ニューラルネットワークの基本単位となる。"
    },
    "マルコフ性": {
        "meaning": "次の状態が現在の状態のみに依存する性質",
        "memo": "現状の状態が分かれば、過去の履歴に関係なく次の状態の予定が可能という性質。"
    },
    "ベイズ情報量基準(BIC)": {
        "meaning": "データ数を加味してモデル複雑性を調整する指標",
        "memo": "AICに比べ、より複雑なモデルに対して強いペナルティを与える。ベイズ推定に基づく。"
    },
    "赤池情報量基準(AIC)": {
        "meaning": "適合度とモデルの複雑さを考慮する評価指標",
        "memo": "パラメータ数にペナルティを加えることで過学習を防ぎ、モデルの予測力に基づいて評価。"
    },
    "情報量基準": {
        "meaning": "モデルの複雑と適合度を両立して評価する指標群",
        "memo": "AICやBICなど、複雑さと性能のバランスを数値化し、モデル選択すべきとする考え方。"
    },
    "オッカムの剃刀": {
        "meaning": "最も単純な仮説を優先すべきという原則",
        "memo": "同等の性能を持つモデルが複数ある場合、より単純なものを選択すべきとする考え方。"
    },
    "ROC曲線": {
        "meaning": "偽陽性率と真陽性率の関係を示した曲線",
        "memo": "分類器の性能を閾値の変化に応じて視覚化。\nAUC(曲線下面積)が性能の尺度になる。"
    },
    "過学習": {
        "meaning": "訓練データへの適合が過ぎて汎化性能が低下する状態",
        "memo": "過剰適合と同義で用いられることが多く、テスト性能の悪化を招く。"
    },
    "過剰適合（オーバーフィッティング）": {
        "meaning": "訓練データに過度に適合し汎化性能が低下する現象",
        "memo": "過剰誤差は小さいが、テストデータで誤差が大きくなる。モデルの複雑さが原因。"
    },
    "偽陰性(FN)": {
        "meaning": "実際は陽性なのに予測は陰性",
        "memo": "訓練誤差は小さいが、テストデータで誤差が大きくなる。モデルの複雑さが原因。"
    },
    "偽陽性(FP)": {
        "meaning": "実際は陰性なのに予測は陽性",
        "memo": "モデルが誤って陰性と予測した件数。"
    },
    "真陰性(TN)": {
        "meaning": "実際は陰性で予測も陰性",
        "memo": "モデルが誤って陽性と予測した件数。"
    },
    "真陽性(TP)": {
        "meaning": "実際に陽性で予測も陽性",
        "memo": "モデルが正しく陰性と判断した件数。"
    },
    "混同行列": {
        "meaning": "予測結果と実際のクラスの関係を表した表",
        "memo": "モデルが正しく陽性と判断した件数。"
    },
    "F値": {
        "meaning": "適合率と再現率の調和平均",
        "memo": "真陽性・偽陽性・真陰性・偽陰性の4つの項目から分類性能を可視化。"
    },
    "再現率": {
        "meaning": "実際の陽性の中で正しく予測できた割合",
        "memo": "PrecisionとRecallのバランスを測る。両者のバランスが重要なタスクで使用。"
    },
    "適合率": {
        "meaning": "陽性と予測した中で実際に正しかった割合",
        "memo": "モデルが陽性と予測した中でどれだけ正解だったかを示す。偽陽性に敏感。"
    },
    "正解率": {
        "meaning": "全体に対する正しく予測された割合",
        "memo": "全予測の中で正解したものの割合。不均衡データでは過大評価の恐れあり。"
    },
    "平均絶対値誤差(MAE)": {
        "meaning": "誤差の絶対値の平均",
        "memo": "外れ値の影響を受けにくい。誤差の平均的な大きさを表す。"
    },
    "二乗平均平方根誤差(RMSE)": {
        "meaning": "MSEの平方根をとった値",
        "memo": "誤差の単位を元データと一致させた指標。直感的に理解しやすい。"
    },
    "平均二乗誤差(MSE)": {
        "meaning": "誤差の２乗の平均値",
        "memo": "大きな誤差に対してペナルティが強く働くため、外れ値に敏感。"
    },
    "予測誤差": {
        "meaning": "モデルの予測値と実測値の差",
        "memo": "モデルの精度を示す基本的な指標。\n具体的な誤差尺度(MSE，RMSEなど)で評価される。"
    },
    "k-分割交差検証": {
        "meaning": "データをk分割して交互に学習・検証を繰り返す手法。",
        "memo": "各分割ごとにモデル学習し、検証結果の平均で性能を評価。k=5や10がよく使われる。"
    },
    "ホールドアウト検証": {
        "meaning": "データを訓練用と検証用に一度だけ分割して評価。",
        "memo": "分割の偏りを平均化し、モデルの汎化性能をより安定して評価できる。"
    },
    "交差検証(クロスバリテーション)": {
        "meaning": "データを複数の分割パターンで学習・評価する検証法。",
        "memo": "単純で高速だが、分割の仕方によって評価が不安定になる可能性がある。"
    },
    "テストデータ": {
        "meaning": "モデルの性能を評価するためのデータ",
        "memo": "訓練に使用していない新規データで、モデルの汎化性能(未見のデータへの対応力)を測定する。"
    },
    "訓練データ": {
        "meaning": "モデルを学習させるために用いるデータ",
        "memo": "モデルのパラメータを最適化するために使用。\n学習フェーズに使われ、精度の評価には使われない。"
    },
    "Actor-Critic": {
        "meaning": "方策と価値観数を分けて学習する手法",
        "memo": "Actorが方策を更新し、Criticが価値観数を学習して勾配を支援。安定性と効率のバランスが取れた手法。"
    },
    "REINFORSE": {
        "meaning": "確率的方策に対する方策勾配アルゴリズム",
        "memo": "方策を確率分布として扱い、報酬を最大化するように勾配更新を行うシンプルな方策勾配法。"
    },
    "方策勾配法": {
        "meaning": "方策を直接最適化する強化学習手法",
        "memo": "方策をパラメータ化し、報酬を最大化するように勾配上昇で更新。"
    },
    "SARSA": {
        "meaning": "実際に選んだ行動に基づいてQ値を更新する手法",
        "memo": "Q学習と異なり、実際に行動した軌跡に基づいてQ値を更新するオンポリシー型手法。"
    },
    "Q学習": {
        "meaning": "行動価値観数を更新して最適方策を得る手法",
        "memo": "Q値を逐次更新しながら最適な方策を学習するオフポリシー型アルゴリズム。"
    },
    "Q値": {
        "meaning": "行動価値観数の値",
        "memo": "状態と行動の組に対する価値。これを用いて最適な行動を決定する。"
    },
    "行動価値観数(Q)": {
        "meaning": "ある状態における将来の報酬の期待値",
        "memo": "特定の状態で特定の行動をとったとき、得られる累積報酬の期待値を表す。"
    },
    "状態価値観数(V)": {
        "meaning": "ある状態や行動の将来の報酬の期待値",
        "memo": "ある状態において方策に従って行動した場合に得られる将来報酬の期待値。"
    },
    "価値観数": {
        "meaning": "ある状態や行動の将来の報酬の期待値",
        "memo": "方策に従って得られる累積報酬の期待値。学習アルゴリズムの基礎として使われる。"
    },
    "マルコフ決定過程(MDP)": {
        "meaning": "状態・行動・報酬の関係を数理モデル化したもの",
        "memo": "状態・行動・報酬・遷移確率・割引率で定義される決定過程。強化学習の理論的基盤となる。"
    },
    "方策(ポリシー)": {
        "meaning": "状態に対してどの行動をとるかを決定する戦略",
        "memo": "エージェントの意思決定ルール。確率的(確率分布で選択)または決定的(常に一定の行動を選択)に定義される。"
    },
    "UCB方策": {
        "meaning": "信頼区間を考慮して選択する方策",
        "memo": "Upper Confidence Bound.\n期待値と不確実性(探索ボーナス)の両方を考慮して行動を選ぶ。"
    },
    "ε-greedy方策": {
        "meaning": "一定確率でランダム選択を行う方策",
        "memo": "εの確率でランダムな行動、1-εの確率で最適な行動を選択。探索と活用のトレードオフを制御する基本的な方策。"
    },
    "バンディットアルゴリズム": {
        "meaning": "選択肢の中から最適な行動を選ぶ手法群",
        "memo": "1ステップごとの意思決定問題。報酬の期待値を推定しながら、探索(exploration)と活用(exploition)のバランスを取る。"
    },
    "割引率(γ)": {
        "meaning": "未来の報酬の現在価値を計算する係数",
        "memo": "将来の報酬の価値を現在の価値に換算するために使われる。０に近いと目先の報酬重視、１に近いと将来重視。"
    },
    "潜在的ディリクレ配分法(LDA)": {
        "meaning": "トピックモデルの代表的な確率モデル",
        "memo": "文書ごとにトピックごとに単語の分布を確率で生成。文書分類や要約に応用される。"
    },
    "トピックモデル": {
        "meaning": "文章中に潜む話題の構造を抽出するモデル群",
        "memo": "文書を複数のトピックに分解し、それぞれがどれくらい含まれているかを確率的に表現する。"
    },
    "コンテンツベースフィルタリング": {
        "meaning": "対称アイテムの特徴に基づいて推薦する方法",
        "memo": "商品の属性情報(ジャンル、価格など)とユーザーの過去の行動を用いて推薦を行う。"
    },
    "コールドスタート問題": {
        "meaning": "データが少ない状況で推薦が困難になる課題",
        "memo": "新規ユーザーや新商品に関する情報がないため、推薦精度が著しく低下する問題。"
    },
    "レコメンデーション": {
        "meaning": "最適なコンテンツや商品を提示する仕組み",
        "memo": "ユーザーの履歴、属性、嗜好に基づき、興味関心の高い情報を自動提示。協調・内容ベースがある。"
    },
    "協調フィルタリング": {
        "meaning": "ユーザーの行動履歴から類似を抽出して推薦",
        "memo": "他のユーザーの嗜好を参考にして推薦を行う。SVDなどの行列分解ベースの手法も含まれる。"
    },
    "t-SNE": {
        "meaning": "高次元データを低次元に可視化する手法",
        "memo": "局所的構造を保ったままデータを2次元3次元空間に写像。クラスタの視覚化に優れる。"
    },
    "多次元尺度構成法(MDS)": {
        "meaning": "類似度から座標空間にマッピングする手法",
        "memo": "データ間の類似性に応じて、低次元空間に配置し、錯覚的にクラスタ構造を捉える。"
    },
    "特異値分解(SVD)": {
        "meaning": "行列を分解して特徴構造を抽出する手法",
        "memo": "任意の行列を直交行列と対角行列に分解。次元削減、圧縮、レコメンデーションにも応用される。"
    },
    "主成分分析(PCA)": {
        "meaning": "データの次元を縮約するための手法",
        "memo": "分散が最大となる方向(主成分)を軸に取り、データの情報をたも保ちながら次元を減らす。"
    },
    "デンドログラム": {
        "meaning": "階層クラスタリングの構造を可視化した図",
        "memo": "クラスタ統合の順序と距離を木構造として表示。\n階層の深さ・分岐の様子が一目でわかる。"
    },
    "最短距離法": {
        "meaning": "最も近い要素同士の距離で久田スタ間距離を定義",
        "memo": "2つのクラスタ間の最小距離に基づいてクラスタ統合を進める。\nリンク法の一種。"
    },
    "ウォード法": {
        "meaning": "分割時の分散増加が最小になるようにクラスタを統合",
        "memo": "クラスタ同士を統合する際に、全体の分散増加を最小にするように選択する階層クラスタリング手法。"
    },
    "階層ありクラスタリング": {
        "meaning": "階層構造を形成しながらクラスタを作る手法",
        "memo": "データ同士を段階的に統合または分割し、階層的に分類。可視化にデンドログラムが使われる。"
    },
    "k-means法": {
        "meaning": "重心の距離でデータを分類するクラスタリング手法",
        "memo": "K個のクラスタ中心を初期設定し、データを最も近い中心に分類→重心再計算を繰り返す。"
    },
    "階層なしクラスタリング": {
        "meaning": "あらかじめ決めた数のグループに分類するクラスタリング手法",
        "memo": "K‐means法などが代表例。事前にクラス数を指定し、データを最も近い中心に分類→重心再計算を繰り返す。"
    },
    "ベクトル自己回帰モデル(VAR)": {
        "meaning": "複数の系列間の相互依存性を扱う時系列モデル",
        "memo": "複数の変数が互いに影響し合う構造をモデル化。経済や多変量データの予測に活用される。"
    },
    "時系列分析": {
        "meaning": "時間に沿ったデータの変動を分析する手法群",
        "memo": "傾向・周期・変動をモデル化して未来予測や異常検知に応用。"
    },
    "時系列データ": {
        "meaning": "時間の順序に従って並んだデータ",
        "memo": "株価、気温、センサーデータなど、時系列的な依存性を持つ情報。"
    },
    "自己回帰モデル(AR)": {
        "meaning": "過去の値に基づいて現在の値を予測する時系列モデル",
        "memo": "現在の値を、過去の値の線形結合で表すモデル。時間依存性を扱う分析の基礎。"
    },
    "カーネルトリック": {
        "meaning": "高次元特徴計算を明示せずに実行する手法",
        "memo": "特徴変換を行わずにカーネル関数だけで高次元内積を計算し、処理を効率化する。"
    },
    "カーネル関数": {
        "meaning": "高次元特徴空間の内積を効率的に計算する関数",
        "memo": "元の特徴空間を高次元に写像し、非線形な分類問題を線形分離可能にする。代表例：RBF、ポリノミアル。"
    },
    "マージン最大化": {
        "meaning": "境界線とデータ点との距離を最大にする考え方。",
        "memo": "分類性能を高めるため、クラス間の「安全領域」を広くとることを目的とする。"
    },
    "サポートベクターマシーン(SVM)": {
        "meaning": "マージン最大化により分類境界を決定する手法",
        "memo": "最も近いデータとの距離(マージン)を最大にする分類器。カーネル法により非線形問題にも対応可能。"
    },
    "XGBoost": {
        "meaning": "高速かつ高精度な勾配ブースティング実装",
        "memo": "並列処理や正則化を取り入れた勾配ブースティングの実用版。Kaggle等のコンペで広く使用さる。"
    },
    "勾配ブースティング": {
        "meaning": "損失関数最小化する方向にモデルを改善する手法",
        "memo": "残渣(誤差)に注目しモデルを逐次学習し、勾配に沿って性能を高める。制度は高いが計算コストも高い。"
    },
    "AdaBoost": {
        "meaning": "誤分類に重みを与えて改善するブースティング手法",
        "memo": "各モデルの重み付けを工夫し、制度の低い弱学習器を連続的に改善して高精度化する。"
    },
    "ブースティング": {
        "meaning": "弱いモデルを連続的に学習して強化する手法",
        "memo": "誤分類されたデータの重みを付け、順次学習して精度を高める。\n代表例：AbaBoost、勾配ブースティング。"
    },
    "バギング": {
        "meaning": "複数のモデルを並列に学習し、予測を平均化する手法",
        "memo": "学習データをブースストラップし、複数モデルの予測を平均・多数決で統合する。過学習を抑える効果あり。"
    },
    "アンサンブル学習": {
        "meaning": "複数の学習器を組み合わせて予測精度を上げる手法",
        "memo": "単一モデルよりも高精度で頑健な予測を可能にする。\n代表例：バギング、ブースティング。"
    },
    "ブートストラップサンプリング": {
        "meaning": "復元抽出によるランダムなサンプリング手法",
        "memo": "同じデータから複数の学習データを生成するために使う。アンサンブル学習の土台。"
    },
    "決定木": {
        "meaning": "条件分岐で予測を行う木構造モデル",
        "memo": "データを条件に基づいて分割し、葉で最終予測を行う。\n可視性に優れ、人の解釈がしやすい。"
    },
    "ランダムフォレスト": {
        "meaning": "複数の決定木を組み合わせたアンサンブル学習",
        "memo": "ブートストラップサンプリングとランダムな特徴選択により、多数の決定木を構築して平均・多数決で予測する。"
    },
    "多クラス分類問題": {
        "meaning": "3つ以上のカテゴリに分類する問題",
        "memo": "手書き数字分類(0から9など)や商品分類に応用される。"
    },
    "2クラス分類問題": {
        "meaning": "2つのカテゴリに分類する問題",
        "memo": "スパム／非スパム、合格／非合格などの２択分類。ロジスティック回帰やSVMで使用。"
    },
    "ソフトマックス関数": {
        "meaning": "多クラス分類にで確率に変換する関数",
        "memo": "各クラスのスコアを正規化して、全体の確率分布として扱う。"
    },
    "シグモイド関数": {
        "meaning": "出力を0～1に収めるS字間数",
        "memo": "ロジスティック回帰やニューラルネットワークで用いられ、確率的解釈が可能になる。"
    },
    "ロジスティック回帰": {
        "meaning": "確率的な2値分類を行う回帰モデル",
        "memo": "シグモイド関数を用いて出力を確率に変換し、閾値で分類する。"
    },
    "リッジ回帰": {
        "meaning": "L 2正則化を加えた線形回帰",
        "memo": "重みの大きさを抑えることで、学習の安定性と汎化性能を向上。"
    },
    "ラッソ回帰": {
        "meaning": "L 1正則化を加えた線形回帰",
        "memo": "特徴量の重みを０にしやすく、重要な変数選択ができる。過学習制御に有効。"
    },
    "重回帰分析": {
        "meaning": "複数の説明関数で目的関数を予測する回帰",
        "memo": "複数の要因が目的変数に与える影響を解析。多次元の線形モデル。"
    },
    "単回帰分析": {
        "meaning": "1つの説明変数で目的関数を予測する回帰",
        "memo": "直接的関係を仮定し、1変数から目的値を推定。\n教師あり学習の基本。"
    },
    "線形回帰": {
        "meaning": "入力と出力の間の線形関係をモデル化する回帰手法。",
        "memo": "目的変数を説明変数の線形結合で表す回帰モデル。\n単回帰・重回帰・正則化回帰(ラッソ、リッジ)などの基本となる。係数は最小二乗法などで推定される。"
    },
    "強化学習": {
        "meaning": "試行錯誤を通じて報酬を最大化する学習手法",
        "memo": "エージェントが環境と相互作用し、報酬を得るように行動を学習。例：囲碁AI、ロボット制御。"
    },
    "教師あり学習": {
        "meaning": "正解データをもとに学習する手法",
        "memo": "入力とそれに対応する正解ラベルを用いて学習。\n分類や回帰などが該当。例：画像ラベル、スパム判定。"
    },
    "教師なし学習": {
        "meaning": "正解データなしで学習する手法",
        "memo": "クラスタリングや次元削減に用いられ、データの構造や傾向を自動で抽出。例：顧客分類、主成分分析。"
    },
    "GPT": {
        "meaning": "自己回帰トランスフォーマーモデル",
        "memo": "Generative Pre-trained Transformer。\n事前学習とファインチューニングの2段階で構築され、文脈を理解し自然な文を生成できる。"
    },
    "ファインチューニング": {
        "meaning": "特定のタスクに応じて再学習する工程",
        "memo": "事前学習済みモデルをベースに、少量のデータで再学習して性能を最適化する。NLP・画像分類など広く使われる。"
    },
    "アテンション": {
        "meaning": "重要な部分に重みを置く仕組み",
        "memo": "入力文の中で意味的に重要な単語に注目する仕組み。\n文脈理解・翻訳精度向上に貢献し、Transfomerの中核をなす。"
    },
    "Attension Is All You Need": {
        "meaning": "Transformerを提案した論文",
        "memo": "2017年に発表された論文で、従来のシーケンスモデルを一新。\n自己注意(Self-Attention)によって圧倒的性能を実現した。"
    },
    "トランスフォーマー(Transformer)": {
        "meaning": "自己注意機構に基づく深層学習モデル",
        "memo": "従来のRNNを超える高性能を持ち、並列処理と長距離依存関係の学習が可能。BERTやGPTなど多くのモデルの基盤となる。"
    },
    "OpenAI": {
        "meaning": "人工知能の研究と開発を行う企業",
        "memo": "非営利で設立され、現在は営利法人と連携しながら、GPTシリーズ・Codex・DALL-Eなどを開発。倫理・安全性にも注力している。"
    },
    "SuperVision": {
        "meaning": "AlexNetとして知られる画像認識モデル",
        "memo": "2012年ILSVRCで圧勝した深層CNNモデル。GPUを活用し、畳込み層とReLU・ドロップアウトを用いて画像認識性能を大幅に向上させた。"
    },
    "ILSVRC": {
        "meaning": "画像認識精度を競う国際コンペティション",
        "memo": "ImageNet Large ScaleVisual Rrcognition Challenge。年次の画像分類競技で、深層学習の飛躍的発展の契機となった。"
    },
    "オートエンコーダー(自己符号化器)": {
        "meaning": "入力をデータを圧縮・再編成するニューラルネットワーク",
        "memo": "中間層に圧縮表現(潜在変数)を学習させ、入力と同じ出力を復元する。次元削減や異常検知、生成モデルの基盤となる。"
    },
    "SAV(サポートベクターマシーン)": {
        "meaning": "分類境界を最大化する機械学習手法",
        "memo": "2クラス分類において、マージン(境界線とデータ点との距離)を最大化することで汎化性能を高める。カーネル法と併用される。"
    },
    "ネオコグニトロン": {
        "meaning": "CNNの原型となる視覚認識モデル",
        "memo": "1980年代に福島邦彦が提案。視覚野の構造を模した階層的モデルで、特徴の抽出と識別を自動化する。"
    },
    "誤差逆伝播法": {
        "meaning": "出力を用いて重みを更新する学習方法",
        "memo": "ニューラルネットワークで出力と正解との差(誤差)を逆方向に伝播させて重みを調整する手法。"
    },
    "パーセプトロン": {
        "meaning": "単純な2値分類を行うニューラルネットワークの基本単位",
        "memo": "1950年代に提案された最初期のモデルで、入力に重みをかけて出力を決定する。多層化することで複雑な関数も学習可能に。"
    },
    "ニューラルネットワーク": {
        "meaning": "脳の神経回路を模倣した学習モデル",
        "memo": "入力・中間・出力層からなる多層構造で、重み調整によりデータの特徴を学習する。画像認識や音声認識、自然学習処理などに応用。"
    },
    "特徴表現学習": {
        "meaning": "データの特徴を自動で抽出・変換する手法群",
        "memo": "従来の手動による特徴量設計を置き換える技術で、ニューラルネットワークやオートエンコーダー、BERTなどが含まれる。特徴を抽象化し、下流タスクに有用な表現を得る。"
    },
    "コーパス": {
        "meaning": "自然言語処理で用いる大量のテキストデータ",
        "memo": "言語モデルの学習や辞書作成などに使用される。構造化され注釈付きのものが多い。例：日本語話し言葉コーパス。"
    },
    "統計的自然言語処理": {
        "meaning": "統計手法を用いた言語処理技術",
        "memo": "単語の出現頻度などに基づく言語処理。ルールベースより柔軟かつ高精度で、翻訳や要約などに応用される。"
    },
    "スパムフィルタ": {
        "meaning": "迷惑メールを手動で検出・排徐する仕組み",
        "memo": "自然言語処理や機械学習により、不要なメールを分類。ベイズ分類器などが代表的な手法として知られる。"
    },
    "レコメンデーションシステム": {
        "meaning": "ユーザーに最適な情報を提示する仕組み",
        "memo": "ユーザーの行動や嗜好に基づき、商品やコンテンツを推薦するAIシステム。協調フィルタリングやコンテンツベースフィルタリングが主流。"
    },
    "ビッグデータ": {
        "meaning": "従来の処理能力を超える巨大なデータ群",
        "memo": "Volume(量)・Variety(多様性)・Velocity(速度)などの特性をもつ。膨大なデータ。AI・機械学習の基盤となる。"
    },
    "東ロボ君": {
        "meaning": "東大合格を目指すAIぷろジェクト",
        "memo": "国立情報学研究所が開発した、大学入試問題を解くAI。知識処理・文章理解・数式処理などを総合的に扱い、偏差値57程度に達した。"
    },
    "ワトソン": {
        "meaning": "IBMが開発したQA型AIシステム",
        "memo": "IBMが開発した質問応答型AI。クイズ番組「Jeopardy!」で人間チャンピオンに勝利。自然言語処理・情報検索・機械学習を組み合わせた。"
    },
    "ライトウェイトオントロジー": {
        "meaning": "簡易な分類やタグ付けを目的としたオントロジー",
        "memo": "主に検索や分類、情報整理などに用いられる。厳密性よりも利便性を優先。例：商品カテゴリー、ブログタグなど。"
    },
    "ヘビーウェイトオントロジー": {
        "meaning": "厳密かつ詳細に定義されたオントロジー",
        "memo": "専門的・学術的な目的で使用され、論理的整合性や精密な分類を重視。例：医学用語、法体系など。"
    },
    "オントロジー": {
        "meaning": "概念や関係の体系的な定義",
        "memo": "ある分野の用語や概念、意味関係を定義して共有可能にする枠組み。意味ネットワークや知識グラフと密接に関連。"
    },
    "part-of": {
        "meaning": "意味ネットワークにおける代表的な関係",
        "memo": "一部である構成要素を表す。(例：手 part-of 体)"
    },
    "is-a": {
        "meaning": "意味ネットワークにおける代表的な関係",
        "memo": "上位・下位の継承関係を表す。(例：犬 is-a 動物)"
    },
    "意味ネットワーク": {
        "meaning": "概念間の意味的つながりを表現した構造",
        "memo": "ノード(概念)とエッジ(関係)で知識を構造的に表現する。"
    },
    "インタビューシステム": {
        "meaning": "対話形式で知識を抽出するシステム",
        "memo": "専門家から知識を引き出すために対話形式で質問を行い、ルールベースに変換するツール。知識獲得のボトルネック緩和が目的。"
    },
    "暗黙知": {
        "meaning": "言語化・形式化が難しい知識",
        "memo": "熟練者の直観や経験値など、明示的に表現できない知識。エキスパートシステムでは、形式知は扱えるが暗黙知の取り扱いが難しい。"
    },
    "マイシン（ＭＹＣＩＮ）": {
        "meaning": "医療診断支援目的としたエキスパートシステム",
        "memo": "1970年代に開発さてた、感染症の診断と治療を行うエキスパートシステム。推論エンジンとルールベースの知識を組み合わせていた。"
    },
    "デンドラル（DENDRAL）": {
        "meaning": "化学構造解析を行う初期のエキスパートシステム",
        "memo": "1960年代にスタンフォード大学で開発された、質量分析データから有機化合物の分子構造を推定するAI。MYCINと並ぶ初期の実用AI。"
    },
    "イライザ（ＥＬＩＺＡ）": {
        "meaning": "初期の人工無能型対話AI",
        "memo": "1960年代に開発された、ユーザーの入力に対しキーワードベースで応答する心理療法士風の対話システム。AIの初期ブームを牽引した。"
    },
    "人工無能": {
        "meaning": "知的に見えるが実際は単純なAI",
        "memo": "高度な知能を持っているように見せかけるが、実際は単純なパターンマッチングやテンプレート応答に基づくAI。ELIZAが代表例。"
    },
    "ブルートフォース": {
        "meaning": "全探索によって解を求める手法",
        "memo": "すべての可能性を試して最適解を見つける。計算量が最大になるが、確実に最適解が得られる。チェスAIなど初期のAIで利用された。"
    },
    "プレイアウト": {
        "meaning": "最終局面までランダムに試行する手法",
        "memo": "ゲームAIが局面ごとに何度もシミュレーション(ランダム対局)を行い、勝敗の平均で手の評価を行う。ＡlphaGoにも使用。"
    },
    "モンテカルロ法": {
        "meaning": "ランダム試行による数値解析手法",
        "memo": "統計的手法で問題を解決するアルゴリズム。囲碁や将棋AIで多くのプレイアウトを通して勝率を見積もる。確率論的に近似解を得る。"
    },
    "βカット": {
        "meaning": "α以上が確定したときの枝剪定",
        "memo": "現在の枝の最小スコアが、既に相手が選ばないと判断された最大スコアを下回る場合、それ以降の探索は不要になる。"
    },
    "αカット": {
        "meaning": "β以下が確定したときの枝剪定",
        "memo": "現在の枝の最大スコアが、既に相手が選ばないと判断された最小スコアを超える場合、それ以降の探索は不要になる。"
    },
    "αβ法": {
        "meaning": "Mini-Max探索の効率化手法",
        "memo": "Ｍｉｎｉ－Ｍａｘ法で明らかに不要な枝の探索を省略することで、計算量を削減。α値は最小限許容でカットする。"
    },
    "Ｍｉｎｉ－Ｍａｘ法": {
        "meaning": "2人対戦ゲームにおける最善手探索法",
        "memo": "プレイヤーが最大利益を、相手が最小利益を得ると仮定して、ゲームを探索する手法。勝率が最大となる手を選択する。"
    },
    "ヒューリスティックな知識": {
        "meaning": "経験則に基づく近似的な判断ルール",
        "memo": "完全な論理や数理モデルではなく、実用的な判断探索に使われる知識。計算資源を抑えて効率的に解を見つける際に使われる。"
    },
    "ＡｌｐｈａＧｏ": {
        "meaning": "囲碁で人間を越えたAI",
        "memo": "DeepMind社が開発。モンテカルロ木探索とディープラーニングを組み合わせ、2016年に囲碁の世界王者に勝利。AIの実力を示した歴史的成果。"
    },
    "積み木の世界": {
        "meaning": "AIのテスト用仮想空間",
        "memo": "限られたルールの中でブロックを操作する仮想空間。SHRDLUなどが使用。意味理解や行動計画を検証する教材として有名。"
    },
    "Ｃｙｃプロジェクト": {
        "meaning": "常識知識を集めた知識ベース構築プロジェクト",
        "memo": "1984年に始動した人工知能プロジェクト日常的な常識知識(例：水は濡れる)を形式化し、推論に活用することを目的とする。"
    },
    "SHRDLU": {
        "meaning": "積み木の世界を操作する初期のAI",
        "memo": "1970年にテリー・ウィノグラードが開発。\n自然言語で積み木を操作できるAIで、NLP・推論・環境知識を組み合わせた先駆例。"
    },
    "STRIPS": {
        "meaning": " AIの行動計画を形式化したモデル",
        "memo": "Stanford Research Institute Probulem Solver の略。状態・前提条件・効果で構成。"
    },
    "プランニング": {
        "meaning": "目的達成のための行動列を立案する手法",
        "memo": "初期状態からゴール状態まで一連の行動を計画するAI技術。\nロボット制御やタスク管理、ゲームAIにも応用される。"
    },
    "ハノイの塔": {
        "meaning": "再帰的思考を必要とする代表的な問題",
        "memo": "探索木の枝を深く進み、行き止まりまで探索したら戻って他の枝へ進む。メモリ効率は良いが、最適解を見逃す可能性がある。"
    },
    "深さ優先探索": {
        "meaning": "1つの分岐を限界まで探査くする方法",
        "memo": "探索木の枝を深く進み、行き止まりまで探索したら戻って他の枝へ進む。メモリ効率は良いが、最適解を見逃す可能性がある。"
    },
    "幅優先探索": {
        "meaning": "起点から近い順に探索する方法",
        "memo": "探索木において、各レベルのノードを順に探索する。最短経路を見つけるのに適しているが、メモリ使用量が多くなる。"
    },
    "場合分け": {
        "meaning": "条件や状況応じて処理を分ける手法",
        "memo": "問題を複数の条件に分解し、それぞれに最適な処理を適用する手法。探索問題の枝分かれに関係する。"
    },
    "探索木": {
        "meaning": "状態の分岐を木構造で表したもの",
        "memo": "問題解決やゲームでの分岐を視覚化"
    },
    "身体性": {
        "meaning": "物理的な身体を持つことが認知機能に及ぼす影響や、その必要性に関する概念。",
        "memo": "物理的な身体を持ち、環境と相互作用することで、知覚や認知が形成されるとする考え方。"
    },
    "中国語の部屋": {
        "meaning": "機械がシンボル操作によって言語的応答を生成できても、それが意味理解を伴うわけではないことを示す思考実験。",
        "memo": "中国語を理解しない人が、マニュアルに従って中国語の質問に適切な回答を返せたとしても、実際には中国語の意味を理解していないのと同様に、AIもシンボル操作だけでは真の意味理解には至らないことを示している。"
    },
    "ＣｈａｔＧＰＴ": {
        "meaning": "OpenAIが開発した、GPTアーキテクチャに基づく対話型AIモデル。",
        "memo": "ユーザーの入力に対して自然な対話を行い、質問応答や文章生成など、多岐にわたるタスクを高精度で実行する。"
    },
    "自然言語処理ＬＬＭ": {
        "meaning": "大量のテキストデータとディープラーニング技術を用いて構築された、大規模な言語モデル。",
        "memo": "人間に近い流暢な文章生成や、文脈を理解した応答が可能で、チャットボットや翻訳、要約などのタスクに利用される。"
    },
    "生成AI": {
        "meaning": "既存のデータを学習し、新しいデータ（画像、テキスト、音声など）を生成する人工知能技術。",
        "memo": "文章の自動生成、画像の創出、音楽の作曲など、多様なコンテンツを自動的に生成する技術で、クリエイティブな分野での応用が進んでいる。"
    },
    "知識獲得のボトルネック": {
        "meaning": "AIが専門家の知識を獲得・構築する際に直面する困難。",
        "memo": "エキスパートシステムの構築において、専門家の知識を明示的に抽出し、データベース化することが難しいという課題を指す。"
    },
    "シンボルクラウンティング問題": {
        "meaning": "AIが記号(シンボル)と実世界の意味をどのように対応付けるかという問題。",
        "memo": "AIが「シマウマ」という記号を処理する際、それが実際のシマウマという動        　　　物を指すことをどのように理解するか、という課題を指す。"
    },
    "弱いAI": {
        "meaning": "特定のタスクに特化し、人間の知能を模倣するが、意識や汎用的な理解を持たないAI。現在広く利用されているAIシステムはこれに該当。",
        "memo": "→ANI(特化型AI・特化型人工知能)"
    },
    "強いAI": {
        "meaning": "人間と同等の知能や意識を持ち、多様なタスクを自律的にこなせるAI。現時点では仮想AI。 ",
        "memo": "→AGI(汎用人工知能)"
    },
    "第五世代コンピュータ": {
        "meaning": "1980年代に日本で推進された、人工知能対応の次世代コンピュータを開発する国家プロジェクト。",
        "memo": "自然言語処理や知識情報処理を可能にするコンピュータの開発を目指し、並列処理技術や論理プログラミングの研究が行われた。"
    },
    "エキスパートシステム": {
        "meaning": "特定の専門知識を持ち、人間の専門家のように推論や判断を行うコンピューターシステム。",
        "memo": "医療診断や故障診断など、特定分野の知識をデータベース化し、ユーザーの質問に対して専門的な回答を提供する。"
    },
    "チューリングテスト": {
        "meaning": "機械が人間と同等の知能を持つかを判定するテスト。",
        "memo": "人間の質問者が、テキストベースの対話を通じて相手が人間か機械かを判別できない場合、その機械は人間と同等の知能を持つとされる。"
    },
    "フレーム問題": {
        "meaning": "AIが必要のない膨大な背景情報まで考慮し、処理が停止してしまう問題。",
        "memo": "AIが「スーパーに行って卵を買う」といった単純なタスクでも、関連しない無数の可能性（例えば、道中での出来事）をすべて考慮しようとしてしまい、結果として処理が追いつかなくなる現象を指す。"
    },
    "トイ・プロブレム": {
        "meaning": "ルールと目的が明確に定まっている単純な問題。",
        "memo": "迷路やオセロのように、ルールとゴールが完全に定まっている問題を指す。これらはAI研究の初期段階でよく用いられ、複雑な現実世界の問題を解決する前の基礎的なテストケースとして利用される。"
    },
    "ダートマス会議": {
        "meaning": "1956年に米国ダートマス大学で開催された、人工知能（AI）研究の起点となった会議。",
        "memo": "参加者： マーヴィン・ミンスキー\n　　　     ジョン・マッカーシー\n　　　　 アレン・ニューウェル\n　　　　 ハーバード・サイモン\n　　　　 クロード・シャノン　など"
    },
    "エニアック": {
        "meaning": "1945年に米国で開発された、世界初の汎用電子計算機。",
        "memo": "約17,468本の真空管を使用し、当時としては高速な計算能力を持ち、軍事計算などに利用された。"
    },
    "AI効果": {
        "meaning": "AI技術の内部の仕組み・原理を理解することによって、機械の知的な振る舞いをただの自動化と解釈する心理的効果。",
        "memo": "→ダニングクルーガー効果"
    },
    "ディープラーニング(深層学習)": {
        "meaning": "多層のニューラルネットワークを用いて、データの特徴を自動的に抽出・学習する機械学習の一分野。",
        "memo": "人間の脳神経回路を模したアルゴリズムを活用し、画像認識や自然言語処理などの高度なタスクを高精度で実現する。"
    },
    "機械学習": {
        "meaning": "コンピューターがデータからパターンを学習し、明示的なプログラムなしにタスクを遂行できる技術。",
        "memo": "大量のデータを解析し、その中から特徴や規則性を見つけ出すことで、予測や分類などのタスクを自動化する。"
    },
    "特徴量": {
        "meaning": "予測や分類に使用される定量的データ（説明変数）（入力データ）",
        "memo": "機械学習アルゴリズムは入力された特徴量(説明変数)から出力(目的変数)との関係を学習する。"
    },
    "ASI(人工超知能)": {
        "meaning": "人間の知能を超える能力を持ったAI",
        "memo": "AIの種類は以上3つがあるが、そのうち「AGI(汎用人工知能)」と「ASI(人　　工超知能)」の2つは、まだ誕生していない仮想のAI。"
    },
    "AGI(汎用人工知能)": {
        "meaning": "さまざまな分野で人間と同様の能力を発揮できるAI",
        "memo": "AIの種類は以上3つがあるが、そのうち「AGI(汎用人工知能)」と「ASI(人工超知能)」の2つは、まだ誕生していない仮想のAI。"
    },
    "ANI(特化型AI・特化型人工知能)": {
        "meaning": "特定の環境や仕事に特化したAI",
        "memo": "現在、広く実用化されている。"
    },
    "人工知能（AI）": {
        "meaning": "人間と同じ知的判断処理能力持つ機械（情報処理システム）",
        "memo": "人工知能のコンセンサス\n・推論　・認識　・判断　・問題解決　・知覚　・言語理解\n※知性が定義できない。(IQ、EO、SQなど解釈が多岐にわたる為）"
    }
}